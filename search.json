[
  {
    "objectID": "pipelines.html",
    "href": "pipelines.html",
    "title": "pipeline",
    "section": "",
    "text": "Transforms applicable to preprocess and feature engineer financial data.\n\nsource\n\n\n\n MyBaseTransformer ()\n\nBase class for my custom transformers\n\npipe = Pipeline([\n    ('base-transformer', MyBaseTransformer())\n])\n\ndf = load_test_df()\npipe.fit_transform(df)[:5,:]\n\narray([[ 2759.02,  2779.27,  2747.27,  2754.48, 26562.  ],\n       [ 2753.11,  2755.36,  2690.69,  2743.45, 38777.  ],\n       [ 2744.83,  2748.58,  2651.23,  2672.8 , 41777.  ],\n       [ 2670.8 ,  2722.9 ,  2657.93,  2680.71, 39034.  ],\n       [ 2675.59,  2692.34,  2627.59,  2663.57, 61436.  ]])\n\n\n\npd.DataFrame(data=pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nOpen_transformed\nHigh_transformed\nLow_transformed\nClose_transformed\nVolume_transformed\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562.0\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777.0\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777.0\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034.0\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436.0\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n ReturnTransformer (periods:int=1)\n\nEvaluate the percentage return over 1 or more periods\n\npipe = ColumnTransformer([\n    ('r', ReturnTransformer(), ['Open', 'Close', 'Volume'])\n])\npd.DataFrame(pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nr__Open_ret\nr__Close_ret\nr__Volume_ret\n\n\ndt\n\n\n\n\n\n\n\n2018-10-22\n0.000000\n0.000000\n0.000000\n\n\n2018-10-23\n-0.002142\n-0.004004\n0.459867\n\n\n2018-10-24\n-0.003008\n-0.025752\n0.077365\n\n\n2018-10-25\n-0.026971\n0.002959\n-0.065658\n\n\n2018-10-26\n0.001793\n-0.006394\n0.573910\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n StdTransformer (window:int=5)\n\nEvaluate the standard deviation over a window\n\npipe = ColumnTransformer([\n    ('returns', StdTransformer(3), ['Open', 'Close'])\n])\npd.DataFrame(data=pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nreturns__Open_std3\nreturns__Close_std3\n\n\ndt\n\n\n\n\n\n\n2018-10-22\nNaN\nNaN\n\n\n2018-10-23\n4.179001\n7.799388\n\n\n2018-10-24\n7.127910\n44.318367\n\n\n2018-10-25\n45.320958\n38.708953\n\n\n2018-10-26\n41.427774\n8.578467\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n MATransformer (window:int=5)\n\nEvaluate the moving average over a window\n\nsource\n\n\n\n\n EMATransformer (window:int=5)\n\nEvaluate the exponential moving average over a window\nBuild a pipeline applying these transforms to specific columns.\n\npipe = ColumnTransformer([\n    ('thru', 'passthrough', ['Open', 'High', 'Low', 'Close', 'Volume']),\n    ('ret', ReturnTransformer(3), ['Close']),\n    ('ma', MATransformer(3), ['Close']),\n    ('ema', EMATransformer(3), ['Open', 'Close'])\n])\npd.DataFrame(data=pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nthru__Open\nthru__High\nthru__Low\nthru__Close\nthru__Volume\nret__Close_ret\nma__Close_MA3\nema__Open_EMA3\nema__Close_EMA3\n\n\ndt\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562.0\n0.000000\n2754.480000\n2759.020000\n2754.480000\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777.0\n0.000000\n2748.965000\n2755.080000\n2747.126667\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777.0\n0.000000\n2723.576667\n2749.222857\n2704.654286\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034.0\n-0.026782\n2698.986667\n2707.397333\n2691.884000\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436.0\n-0.029117\n2672.360000\n2690.980645\n2677.270323\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n simplify_colnames (cols)\n\nSimplify the columns names by removing the prefix\n\nprint(pipe.get_feature_names_out())\n\n['thru__Open' 'thru__High' 'thru__Low' 'thru__Close' 'thru__Volume'\n 'ret__Close_ret' 'ma__Close_MA3' 'ema__Open_EMA3' 'ema__Close_EMA3']\n\n\n\nprint(simplify_colnames(pipe.get_feature_names_out()))\n\n['Open', 'High', 'Low', 'Close', 'Volume', 'Close_ret', 'Close_MA3', 'Open_EMA3', 'Close_EMA3']\n\n\n\ndf_proc = pd.DataFrame(\n    data=pipe.fit_transform(df), \n    columns=simplify_colnames(pipe.get_feature_names_out()), \n    index=df.index)\ndf_proc.head(5)\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nClose_ret\nClose_MA3\nOpen_EMA3\nClose_EMA3\n\n\ndt\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562.0\n0.000000\n2754.480000\n2759.020000\n2754.480000\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777.0\n0.000000\n2748.965000\n2755.080000\n2747.126667\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777.0\n0.000000\n2723.576667\n2749.222857\n2704.654286\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034.0\n-0.026782\n2698.986667\n2707.397333\n2691.884000\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436.0\n-0.029117\n2672.360000\n2690.980645\n2677.270323",
    "crumbs": [
      "pipeline"
    ]
  },
  {
    "objectID": "pipelines.html#custom-transforms",
    "href": "pipelines.html#custom-transforms",
    "title": "pipeline",
    "section": "",
    "text": "Transforms applicable to preprocess and feature engineer financial data.\n\nsource\n\n\n\n MyBaseTransformer ()\n\nBase class for my custom transformers\n\npipe = Pipeline([\n    ('base-transformer', MyBaseTransformer())\n])\n\ndf = load_test_df()\npipe.fit_transform(df)[:5,:]\n\narray([[ 2759.02,  2779.27,  2747.27,  2754.48, 26562.  ],\n       [ 2753.11,  2755.36,  2690.69,  2743.45, 38777.  ],\n       [ 2744.83,  2748.58,  2651.23,  2672.8 , 41777.  ],\n       [ 2670.8 ,  2722.9 ,  2657.93,  2680.71, 39034.  ],\n       [ 2675.59,  2692.34,  2627.59,  2663.57, 61436.  ]])\n\n\n\npd.DataFrame(data=pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nOpen_transformed\nHigh_transformed\nLow_transformed\nClose_transformed\nVolume_transformed\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562.0\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777.0\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777.0\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034.0\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436.0\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n ReturnTransformer (periods:int=1)\n\nEvaluate the percentage return over 1 or more periods\n\npipe = ColumnTransformer([\n    ('r', ReturnTransformer(), ['Open', 'Close', 'Volume'])\n])\npd.DataFrame(pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nr__Open_ret\nr__Close_ret\nr__Volume_ret\n\n\ndt\n\n\n\n\n\n\n\n2018-10-22\n0.000000\n0.000000\n0.000000\n\n\n2018-10-23\n-0.002142\n-0.004004\n0.459867\n\n\n2018-10-24\n-0.003008\n-0.025752\n0.077365\n\n\n2018-10-25\n-0.026971\n0.002959\n-0.065658\n\n\n2018-10-26\n0.001793\n-0.006394\n0.573910\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n StdTransformer (window:int=5)\n\nEvaluate the standard deviation over a window\n\npipe = ColumnTransformer([\n    ('returns', StdTransformer(3), ['Open', 'Close'])\n])\npd.DataFrame(data=pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nreturns__Open_std3\nreturns__Close_std3\n\n\ndt\n\n\n\n\n\n\n2018-10-22\nNaN\nNaN\n\n\n2018-10-23\n4.179001\n7.799388\n\n\n2018-10-24\n7.127910\n44.318367\n\n\n2018-10-25\n45.320958\n38.708953\n\n\n2018-10-26\n41.427774\n8.578467\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n MATransformer (window:int=5)\n\nEvaluate the moving average over a window\n\nsource\n\n\n\n\n EMATransformer (window:int=5)\n\nEvaluate the exponential moving average over a window\nBuild a pipeline applying these transforms to specific columns.\n\npipe = ColumnTransformer([\n    ('thru', 'passthrough', ['Open', 'High', 'Low', 'Close', 'Volume']),\n    ('ret', ReturnTransformer(3), ['Close']),\n    ('ma', MATransformer(3), ['Close']),\n    ('ema', EMATransformer(3), ['Open', 'Close'])\n])\npd.DataFrame(data=pipe.fit_transform(df), columns=pipe.get_feature_names_out(), index=df.index).head(5)\n\n\n\n\n\n\n\n\nthru__Open\nthru__High\nthru__Low\nthru__Close\nthru__Volume\nret__Close_ret\nma__Close_MA3\nema__Open_EMA3\nema__Close_EMA3\n\n\ndt\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562.0\n0.000000\n2754.480000\n2759.020000\n2754.480000\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777.0\n0.000000\n2748.965000\n2755.080000\n2747.126667\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777.0\n0.000000\n2723.576667\n2749.222857\n2704.654286\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034.0\n-0.026782\n2698.986667\n2707.397333\n2691.884000\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436.0\n-0.029117\n2672.360000\n2690.980645\n2677.270323\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n simplify_colnames (cols)\n\nSimplify the columns names by removing the prefix\n\nprint(pipe.get_feature_names_out())\n\n['thru__Open' 'thru__High' 'thru__Low' 'thru__Close' 'thru__Volume'\n 'ret__Close_ret' 'ma__Close_MA3' 'ema__Open_EMA3' 'ema__Close_EMA3']\n\n\n\nprint(simplify_colnames(pipe.get_feature_names_out()))\n\n['Open', 'High', 'Low', 'Close', 'Volume', 'Close_ret', 'Close_MA3', 'Open_EMA3', 'Close_EMA3']\n\n\n\ndf_proc = pd.DataFrame(\n    data=pipe.fit_transform(df), \n    columns=simplify_colnames(pipe.get_feature_names_out()), \n    index=df.index)\ndf_proc.head(5)\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nClose_ret\nClose_MA3\nOpen_EMA3\nClose_EMA3\n\n\ndt\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562.0\n0.000000\n2754.480000\n2759.020000\n2754.480000\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777.0\n0.000000\n2748.965000\n2755.080000\n2747.126667\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777.0\n0.000000\n2723.576667\n2749.222857\n2704.654286\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034.0\n-0.026782\n2698.986667\n2707.397333\n2691.884000\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436.0\n-0.029117\n2672.360000\n2690.980645\n2677.270323",
    "crumbs": [
      "pipeline"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myquantlab",
    "section": "",
    "text": "This package is a work in continuous progress and I will keep adding new features as I develop them.\nThese changes may break things.\nI will try to keep the main branch as clean as possible, but no guarantees are made ðŸ˜Š !",
    "crumbs": [
      "myquantlab"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "myquantlab",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/vtecftwy/myquantlab.git\nLater will be possible to install from PyPI: myquantlab or conda myquantlab.\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repositoryâ€™s pages.",
    "crumbs": [
      "myquantlab"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "myquantlab",
    "section": "How to use",
    "text": "How to use\nWork in Progress",
    "crumbs": [
      "myquantlab"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "Set of functions that are transferred from my former package finutilities\n\nsource\n\n\n\n safe_date (dt:str|datetime.datetime)\n\n*Return a datetime object from string or datetime\nAccepted formats:\n\nâ€˜YYYY-MM-DDâ€™, â€˜YYYY/MM/DDâ€™, â€˜YYYY.MM.DDâ€™\nâ€˜HH:MM:SSâ€™ can be added to the above formats*\n\n\n\n\n\nType\nDetails\n\n\n\n\ndt\nstr | datetime.datetime\ndate time to validate or convert\n\n\nReturns\ndatetime\ndatetime type object\n\n\n\nThis function converts date-time strings into a datetime object, as long as the strings are in one of the following formats:\n\n2024-12-15 21:02:17\n2024/12/15 21:02:17\n2024.12.15 21:02:17\n2024-12-15\n2024/12/15\n2024.12.15\n\nThe function also accepts a datetime as argument dt and can be used to ensure a data argument used in a function is a datetime object.\n\nassert isinstance(safe_date('2024-12-15 21:02:17'), datetime)\nassert isinstance(safe_date('2024/12/15 21:02:17'), datetime)\nassert isinstance(safe_date('2024.12.15 21:02:17'), datetime)\nassert isinstance(safe_date('2024-12-15'), datetime)\nassert isinstance(safe_date('2024/12/15'), datetime)\nassert isinstance(safe_date('2024.12.15'), datetime)\nassert isinstance(safe_date(datetime.now()), datetime)\n\n\nsource\n\n\n\n\n time_slice_df (df:pandas.core.frame.DataFrame,\n                start:str|datetime.datetime|None=None,\n                end:str|datetime.datetime|None=None)\n\nSlices DataFrameâ€™s rows from start to end, or the closest datetime available in the DataTimeIndex.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndf that will be sliced, must have a DateTimeIndex\n\n\nstart\nstr | datetime.datetime | None\nNone\nstart date for slicing\n\n\nend\nstr | datetime.datetime | None\nNone\nend date for slicing\n\n\nReturns\nDataFrame\n\nsliced df\n\n\n\nEven if we pass start and end dates that are not in the datafrane DateTimeIndex, the function still will slice using the closest datetime(s) in the index.\nLetâ€™s take an test dataframe for illustration.\n\nsource\n\n\n\n\n load_test_df ()\n\n\ndf = load_test_df()\ndf.iloc[:15, :]\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436\n\n\n2018-10-29\n2667.70\n2707.00\n2603.33\n2639.17\n44960\n\n\n2018-10-30\n2639.55\n2689.50\n2633.05\n2688.50\n52786\n\n\n2018-10-31\n2688.88\n2736.76\n2681.25\n2704.75\n32374\n\n\n2018-11-01\n2707.13\n2741.58\n2706.88\n2731.90\n29565\n\n\n2018-11-02\n2725.28\n2766.28\n2699.96\n2723.76\n41892\n\n\n2018-11-05\n2721.51\n2744.41\n2713.14\n2740.26\n25161\n\n\n2018-11-06\n2739.39\n2761.53\n2730.14\n2759.15\n20481\n\n\n2018-11-07\n2757.28\n2816.63\n2745.53\n2815.88\n29723\n\n\n2018-11-08\n2814.76\n2817.01\n2794.68\n2805.02\n18369\n\n\n2018-11-09\n2803.40\n2810.15\n2763.78\n2778.60\n25123\n\n\n\n\n\n\n\nIn this example, the DataFrame misses a few days, e.g.: - 2018-10-27 and 2018-10-28 - 2018-11-03 and 2018-11-04\nIf we pick one of these dates for start and end respectively, we still get a sampled dataframe with the closed existing dates:\n\ntime_slice_df(df, '2018-10-27', '2018-11-04')\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-29\n2667.70\n2707.00\n2603.33\n2639.17\n44960\n\n\n2018-10-30\n2639.55\n2689.50\n2633.05\n2688.50\n52786\n\n\n2018-10-31\n2688.88\n2736.76\n2681.25\n2704.75\n32374\n\n\n2018-11-01\n2707.13\n2741.58\n2706.88\n2731.90\n29565\n\n\n2018-11-02\n2725.28\n2766.28\n2699.96\n2723.76\n41892",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "core.html#legacy-function-from-former-package-finutilities",
    "href": "core.html#legacy-function-from-former-package-finutilities",
    "title": "core",
    "section": "",
    "text": "Set of functions that are transferred from my former package finutilities\n\nsource\n\n\n\n safe_date (dt:str|datetime.datetime)\n\n*Return a datetime object from string or datetime\nAccepted formats:\n\nâ€˜YYYY-MM-DDâ€™, â€˜YYYY/MM/DDâ€™, â€˜YYYY.MM.DDâ€™\nâ€˜HH:MM:SSâ€™ can be added to the above formats*\n\n\n\n\n\nType\nDetails\n\n\n\n\ndt\nstr | datetime.datetime\ndate time to validate or convert\n\n\nReturns\ndatetime\ndatetime type object\n\n\n\nThis function converts date-time strings into a datetime object, as long as the strings are in one of the following formats:\n\n2024-12-15 21:02:17\n2024/12/15 21:02:17\n2024.12.15 21:02:17\n2024-12-15\n2024/12/15\n2024.12.15\n\nThe function also accepts a datetime as argument dt and can be used to ensure a data argument used in a function is a datetime object.\n\nassert isinstance(safe_date('2024-12-15 21:02:17'), datetime)\nassert isinstance(safe_date('2024/12/15 21:02:17'), datetime)\nassert isinstance(safe_date('2024.12.15 21:02:17'), datetime)\nassert isinstance(safe_date('2024-12-15'), datetime)\nassert isinstance(safe_date('2024/12/15'), datetime)\nassert isinstance(safe_date('2024.12.15'), datetime)\nassert isinstance(safe_date(datetime.now()), datetime)\n\n\nsource\n\n\n\n\n time_slice_df (df:pandas.core.frame.DataFrame,\n                start:str|datetime.datetime|None=None,\n                end:str|datetime.datetime|None=None)\n\nSlices DataFrameâ€™s rows from start to end, or the closest datetime available in the DataTimeIndex.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndf that will be sliced, must have a DateTimeIndex\n\n\nstart\nstr | datetime.datetime | None\nNone\nstart date for slicing\n\n\nend\nstr | datetime.datetime | None\nNone\nend date for slicing\n\n\nReturns\nDataFrame\n\nsliced df\n\n\n\nEven if we pass start and end dates that are not in the datafrane DateTimeIndex, the function still will slice using the closest datetime(s) in the index.\nLetâ€™s take an test dataframe for illustration.\n\nsource\n\n\n\n\n load_test_df ()\n\n\ndf = load_test_df()\ndf.iloc[:15, :]\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436\n\n\n2018-10-29\n2667.70\n2707.00\n2603.33\n2639.17\n44960\n\n\n2018-10-30\n2639.55\n2689.50\n2633.05\n2688.50\n52786\n\n\n2018-10-31\n2688.88\n2736.76\n2681.25\n2704.75\n32374\n\n\n2018-11-01\n2707.13\n2741.58\n2706.88\n2731.90\n29565\n\n\n2018-11-02\n2725.28\n2766.28\n2699.96\n2723.76\n41892\n\n\n2018-11-05\n2721.51\n2744.41\n2713.14\n2740.26\n25161\n\n\n2018-11-06\n2739.39\n2761.53\n2730.14\n2759.15\n20481\n\n\n2018-11-07\n2757.28\n2816.63\n2745.53\n2815.88\n29723\n\n\n2018-11-08\n2814.76\n2817.01\n2794.68\n2805.02\n18369\n\n\n2018-11-09\n2803.40\n2810.15\n2763.78\n2778.60\n25123\n\n\n\n\n\n\n\nIn this example, the DataFrame misses a few days, e.g.: - 2018-10-27 and 2018-10-28 - 2018-11-03 and 2018-11-04\nIf we pick one of these dates for start and end respectively, we still get a sampled dataframe with the closed existing dates:\n\ntime_slice_df(df, '2018-10-27', '2018-11-04')\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-29\n2667.70\n2707.00\n2603.33\n2639.17\n44960\n\n\n2018-10-30\n2639.55\n2689.50\n2633.05\n2688.50\n52786\n\n\n2018-10-31\n2688.88\n2736.76\n2681.25\n2704.75\n32374\n\n\n2018-11-01\n2707.13\n2741.58\n2706.88\n2731.90\n29565\n\n\n2018-11-02\n2725.28\n2766.28\n2699.96\n2723.76\n41892",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "ohlcv.html",
    "href": "ohlcv.html",
    "title": "ohlcv",
    "section": "",
    "text": "Functions to plot times series in OHLC format (Open, High, Low, Close) and OHLCV format (same + volume).\n\nsource\n\n\n\n candlestick_plot (df:pandas.core.frame.DataFrame, width:int=950,\n                   height:int=600, chart_title:str='',\n                   fig:bokeh.plotting._figure.figure|None=None)\n\nCreate a candlestick chart (Bokeh) using a dataframe with â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™, â€˜Volumeâ€™.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndf with datetime index, and at least following columns â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™, â€˜Volumeâ€™\n\n\nwidth\nint\n950\nheight of the plot figure\n\n\nheight\nint\n600\nheight of the plot figure\n\n\nchart_title\nstr\n\ntitle of the chart\n\n\nfig\nbokeh.plotting._figure.figure | None\nNone\nfigure to allow superposition of other lines on candlestick plot\n\n\nReturns\nNone\n\n\n\n\n\nBefore using the function in a notebook, you must load BokehJS, with:\n\noutput_notebook()\n\n    \n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\nLetâ€™s load a test DataFrame and plot it.\n\ndf = load_test_df()\ndisplay(df.head(10))\ncandlestick_plot(df.head(10), width=800, height=400, chart_title='Candlestick plot')\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436\n\n\n2018-10-29\n2667.70\n2707.00\n2603.33\n2639.17\n44960\n\n\n2018-10-30\n2639.55\n2689.50\n2633.05\n2688.50\n52786\n\n\n2018-10-31\n2688.88\n2736.76\n2681.25\n2704.75\n32374\n\n\n2018-11-01\n2707.13\n2741.58\n2706.88\n2731.90\n29565\n\n\n2018-11-02\n2725.28\n2766.28\n2699.96\n2723.76\n41892\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\nNote that the plot uses a full DateTimeIndex x axis, and the missing bars will just be empty. This allows to compare plots for time series with different missing bars",
    "crumbs": [
      "ohlcv"
    ]
  },
  {
    "objectID": "ohlcv.html#plotting-ohlc-data",
    "href": "ohlcv.html#plotting-ohlc-data",
    "title": "ohlcv",
    "section": "",
    "text": "Functions to plot times series in OHLC format (Open, High, Low, Close) and OHLCV format (same + volume).\n\nsource\n\n\n\n candlestick_plot (df:pandas.core.frame.DataFrame, width:int=950,\n                   height:int=600, chart_title:str='',\n                   fig:bokeh.plotting._figure.figure|None=None)\n\nCreate a candlestick chart (Bokeh) using a dataframe with â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™, â€˜Volumeâ€™.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndf with datetime index, and at least following columns â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™, â€˜Volumeâ€™\n\n\nwidth\nint\n950\nheight of the plot figure\n\n\nheight\nint\n600\nheight of the plot figure\n\n\nchart_title\nstr\n\ntitle of the chart\n\n\nfig\nbokeh.plotting._figure.figure | None\nNone\nfigure to allow superposition of other lines on candlestick plot\n\n\nReturns\nNone\n\n\n\n\n\nBefore using the function in a notebook, you must load BokehJS, with:\n\noutput_notebook()\n\n    \n    \n        \n        Loading BokehJS ...\n    \n\n\n\n\n\nLetâ€™s load a test DataFrame and plot it.\n\ndf = load_test_df()\ndisplay(df.head(10))\ncandlestick_plot(df.head(10), width=800, height=400, chart_title='Candlestick plot')\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\ndt\n\n\n\n\n\n\n\n\n\n2018-10-22\n2759.02\n2779.27\n2747.27\n2754.48\n26562\n\n\n2018-10-23\n2753.11\n2755.36\n2690.69\n2743.45\n38777\n\n\n2018-10-24\n2744.83\n2748.58\n2651.23\n2672.80\n41777\n\n\n2018-10-25\n2670.80\n2722.90\n2657.93\n2680.71\n39034\n\n\n2018-10-26\n2675.59\n2692.34\n2627.59\n2663.57\n61436\n\n\n2018-10-29\n2667.70\n2707.00\n2603.33\n2639.17\n44960\n\n\n2018-10-30\n2639.55\n2689.50\n2633.05\n2688.50\n52786\n\n\n2018-10-31\n2688.88\n2736.76\n2681.25\n2704.75\n32374\n\n\n2018-11-01\n2707.13\n2741.58\n2706.88\n2731.90\n29565\n\n\n2018-11-02\n2725.28\n2766.28\n2699.96\n2723.76\n41892\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\nNote that the plot uses a full DateTimeIndex x axis, and the missing bars will just be empty. This allows to compare plots for time series with different missing bars",
    "crumbs": [
      "ohlcv"
    ]
  },
  {
    "objectID": "ohlcv.html#handling-olhcv-data",
    "href": "ohlcv.html#handling-olhcv-data",
    "title": "ohlcv",
    "section": "Handling OLHCV data",
    "text": "Handling OLHCV data\nFunction performing transformation and analysis on OLHCV data.\n\nsource\n\nresample_ohlcv\n\n resample_ohlcv (df:pandas.core.frame.DataFrame, rule_str='W-FRI')\n\n*Resample a DataFrame with OHLCV format according to given rule string.\nThe re-sampling is applied to each of the OHLC and optional V column. Re-sampling aggregate applies first(), max(), min(), last() and sum() to OHLCV respectively.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndf with datetime index, and at least following columns â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™. Optional â€˜Volumeâ€™\n\n\nrule_str\nstr\nW-FRI\nDateOffset alias for resampling. Default: â€˜W-FRIâ€™. Other commons: â€˜Dâ€™, â€˜Bâ€™, â€˜Wâ€™, â€˜Mâ€™\n\n\nReturns\nDataFrame\n\nresampled df with columns â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™. Optional â€˜Volumeâ€™\n\n\n\nThe list of all DateOffset string reference can be found in Pandasâ€™ documentation here.\nThe test df has one bar (row) for each day. We can resample to aggregate data per week, where one week ends on Friday.\n\ndf_wk = resample_ohlcv(df, rule_str='W-FRI')\ndf_wk.head(5)\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\nW-FRI\n\n\n\n\n\n\n\n\n\n2018-10-26\n2759.02\n2779.27\n2627.59\n2663.57\n207586\n\n\n2018-11-02\n2667.70\n2766.28\n2603.33\n2723.76\n201577\n\n\n2018-11-09\n2721.51\n2817.01\n2713.14\n2778.60\n118857\n\n\n2018-11-16\n2777.10\n2794.23\n2669.14\n2740.15\n170290\n\n\n2018-11-23\n2732.15\n2746.53\n2625.66\n2630.36\n132017\n\n\n\n\n\n\n\n\nprint('Days of the week for initial df:',list(df.index.day_of_week[:5]))\nprint('Days of the week for sampled df:',list(df_wk.index.day_of_week[:5]))\n\nDays of the week for initial df: [0, 1, 2, 3, 4]\nDays of the week for sampled df: [4, 4, 4, 4, 4]\n\n\n\nsource\n\n\nautocorrelation_ohlcv\n\n autocorrelation_ohlcv (df:pandas.core.frame.DataFrame, max_lag:int=10,\n                        ohlc_col:str='Close')\n\nReturn autocorrelation for a range of lags and for the selected ohlc_col_col defined.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\ndf with DateTimeIndex, with Open, High, Low, Close\n\n\nmax_lag\nint\n10\nMaximum lag to consider for the autocorrelation\n\n\nohlc_col\nstr\nClose\nColumns to use for the autocorrelation. Default: â€˜Closeâ€™. Options: â€˜Openâ€™, â€˜Highâ€™, â€˜Lowâ€™, â€˜Closeâ€™\n\n\nReturns\nSeries\n\n\n\n\n\n\nautocorrelation_ohlcv(df, max_lag=5, ohlc_col='Open')\n\n1    0.948029\n2    0.884840\n3    0.826346\n4    0.764883\n5    0.713426\nName: Autocorrelation, dtype: float64",
    "crumbs": [
      "ohlcv"
    ]
  },
  {
    "objectID": "plotting.html",
    "href": "plotting.html",
    "title": "plotting",
    "section": "",
    "text": "source\n\nplot_timeseries\n\n plot_timeseries (*tseries:pandas.core.series.Series,\n                  ax:Optional[matplotlib.axes._axes.Axes]=None,\n                  add_legend:bool=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntseries\nSeries\n\n\n\n\nax\nOptional\nNone\n\n\n\nadd_legend\nbool\nFalse\n\n\n\nReturns\nNone\n\none of several np.Series with DataTimeIndexaxis to plot add legend to plot, when True\n\n\n\n\ndf = load_test_df()\nplot_timeseries(df.Low, df.Close, df.High, add_legend=True)\n\n\n\n\n\n\n\n\n\nsource\n\n\nhist_timeseries\n\n hist_timeseries (*tseries:pandas.core.series.Series,\n                  ax:Optional[matplotlib.axes._axes.Axes]=None)\n\n\nhist_timeseries(df.Low)\n\n\n\n\n\n\n\n\n\nsource\n\n\nplot_acfs\n\n plot_acfs (*tseries, incl_lag0=False, alpha=0.05, ax=None)\n\n\nplot_acfs(df.Close, df.High)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\nnormal_probability_plot\n\n normal_probability_plot (*tseries, ax=None)\n\n\nnormal_probability_plot(df.Close.pct_change().dropna(), df.High.pct_change().dropna())",
    "crumbs": [
      "plotting"
    ]
  }
]